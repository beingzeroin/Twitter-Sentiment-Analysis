{
  "name": "Twitter-sentiment-analysis",
  "tagline": "",
  "body": "# Twitter Sentiment Analysis\r\n------------------------------\r\n## Problem statement\r\nThis project aims to extract the features of tweets and analyze the opinion of tweets as positive, negative or neutral.\r\n- Input: Textual content of a tweet\r\n- Output: Label signifying if the sentiment of the tweet is positive/negative/neutral\r\n\r\n## Motivation\r\nTweets sometimes express opinions about different topics. These opinions are important in many business-related decisions and even political sentiments about a candidate.\r\n- Consumers can use sentiment analysis to research products or services before making a purchase. E.g. Kindle\r\n- Marketers can use this to research public opinion of their company and products, or to analyze customer satisfaction. E.g. Election Polls\r\n- Organizations can also use this to gather critical feedback about problems in newly released products. E.g. Brand Management (Nike, Adidas)\r\n\r\n## Challenges faced\r\n- Noisy text (Misspellings, lack of grammar)\r\n- Lack of context\r\n- Acronyms e.g: lol, brb, gr8\r\n- Emoticons e.g: :), :(\r\n- Negation\r\n\r\n## Pipeline for approach used\r\n![Pipeline](https://raw.githubusercontent.com/goutamnair7/Twitter-Sentiment-Analysis/master/Twitter%20Sentiment%20Analyzer.png)\r\n\r\n### Tweet downloader\r\n- Download the tweets using twitter API (https://github.com/aritter/twitter_download).\r\n- 9684 training and 8987 testing tweets are downloaded.\r\n\r\n### Parser\r\n- The parser removes all unavailable tweets from the downloaded data\r\n- After removing these we have 7612 tweets for training and 7868 tweets for testing\r\n\r\n### Pre-processing\r\n- Replace Emoticons by their polarity.\r\n- Remove URLs and Targets.\r\n- Expand acronyms. eg 'brb' to 'be right back'\r\n- Remove stop words\r\n- Tokenization\r\n- Stemming\r\n- Case-folding\r\n- Remove punctuation marks\r\n- Replace sequence of repeating characters eg. 'hellooooo' by 'helloo'\r\n\r\n### Feature Extraction\r\n- The pre-processed data file is fed to the feature extractor which creates the feature vector.\r\n- The basic (baseline) feature was the unigram model\r\n- A list of all unique unigrams across the training set was constructed and it formed the basic vector for each tweet.\r\n\r\n### Additional Features\r\n- Polarity scores of the tweets\r\n- Negation\r\n- Hashtags\r\n- Special characters (?,!,*)\r\n- Capitalized words\r\n- Bigrams\r\n\r\n### SVM Classification and Prediction\r\n- The features extracted are passed to the classifier\r\n- The model built is used to predict the sentiment of the new tweets\r\n\r\n## Results\r\n\r\nFeatures | Accuracy | Precision | Recall | F1 score\r\n-------- | -------- | --------- | ------ | --------\r\nUnigram  | 54.855%  | 0.5264    | 0.5061 | 0.5125\r\nUnigram + Additional Features | 57.079% | 0.5524 | 0.5308 | 0.5385\r\nBigram   | 58.579%  | 0.5713    | 0.5172 | 0.5268\r\nBigram  + Additional Features | 60.739% | 0.5930 | 0.5525 | 0.5637\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}